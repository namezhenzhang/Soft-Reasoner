{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 21.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_rules(filename):\n",
    "    '''所有id下，所有rules'''\n",
    "    with open(filename, \"r+\", encoding=\"utf8\") as f:\n",
    "        rules = []\n",
    "        reader = jsonlines.Reader(f)\n",
    "        for item in reader:\n",
    "            rules_per_id = []\n",
    "            for key in item[\"rules\"].keys():\n",
    "                rules_per_id.append(item[\"rules\"][key][\"representation\"])\n",
    "            rules.append(rules_per_id)\n",
    "    return rules\n",
    "\n",
    "\n",
    "def get_facts(filename):\n",
    "    '''所有id下，所有facts'''\n",
    "    with open(filename, \"r+\", encoding=\"utf8\") as f:\n",
    "        facts = []\n",
    "        reader = jsonlines.Reader(f)\n",
    "        for item in reader:\n",
    "            facts_per_id = []\n",
    "            for key in item[\"triples\"].keys():\n",
    "                facts_per_id.append(item[\"triples\"][key][\"representation\"])\n",
    "            facts.append(facts_per_id)\n",
    "    return facts\n",
    "\n",
    "\n",
    "def get_qs(filename):\n",
    "    '''所有id下，所有facts'''\n",
    "    with open(filename, \"r+\", encoding=\"utf8\") as f:\n",
    "        qs = []\n",
    "        reader = jsonlines.Reader(f)\n",
    "        for item in reader:\n",
    "            qs_per_id = []\n",
    "            for key in item[\"questions\"].keys():\n",
    "                qs_per_id.append(item[\"questions\"][key][\"representation\"])\n",
    "            qs.append(qs_per_id)\n",
    "    return qs\n",
    "\n",
    "\n",
    "def get_if_then_pairs(rules):\n",
    "    rules_pairs = []\n",
    "    for id in rules:\n",
    "        rules_pair_per_id = []\n",
    "        for rule in id:\n",
    "            matchObj = re.match( r'\\(\\((.*)\\)\\s->\\s\\((.*)\\)\\)', rule, re.M|re.I)\n",
    "            if_list = []\n",
    "            then_list = []\n",
    "            if matchObj:\n",
    "                if_ = matchObj.group(1)\n",
    "                if if_[0]=='(':\n",
    "                    # 提取多个条件\n",
    "                    if_count = if_.count('(')\n",
    "                    regular = (r'\\((.+)\\)\\s'*if_count)[:-2]\n",
    "                    match_if = re.match(regular, if_, re.M|re.I)\n",
    "                    for if_item in range(if_count):\n",
    "                        if_list.append(match_if.group(if_item+1))\n",
    "                else: \n",
    "                    # 添加单个条件\n",
    "                    print('error')\n",
    "                    exit(1)\n",
    "                then_ = matchObj.group(2)\n",
    "                if then_[0]=='(':\n",
    "                    # 提取多个结果\n",
    "                    print('error')\n",
    "                    exit(2)\n",
    "                else:\n",
    "                    # 添加单个结果\n",
    "                    then_list.append(then_)\n",
    "            else:\n",
    "                print('fail',rule)\n",
    "                exit(3)\n",
    "            rules_pair_per_id.append([if_list,then_list])\n",
    "        rules_pairs.append(rules_pair_per_id)\n",
    "    return rules_pairs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class node:\n",
    "    def __init__(self, if_then_pair, type_):\n",
    "        # self.if_ = if_\n",
    "        # self.then_ = then_\n",
    "        self.if_then_pair = if_then_pair\n",
    "        self.type_ = type_\n",
    "        self.sub = None\n",
    "        self.deep = None\n",
    "        self.next_step_list = None\n",
    "        if type_ == 'rule':\n",
    "            self.init_rule(if_then_pair)\n",
    "        if type_ == 'ques':\n",
    "            self.init_ques(if_then_pair)\n",
    "        if type_ == 'fact':\n",
    "            self.init_fact(if_then_pair)\n",
    "\n",
    "\n",
    "    def init_fact(self, if_then_pair):\n",
    "        self.if_ = []\n",
    "        # 替换成sen-polar对\n",
    "        self.then_ = (if_then_pair[1:-4], if_then_pair[-3])\n",
    "\n",
    "\n",
    "    def init_ques(self, if_then_pair):\n",
    "\n",
    "        self.then_ = None\n",
    "\n",
    "        # 替换成sen-polar对\n",
    "        self.if_ = [(if_then_pair[1:-4], if_then_pair[-3])]\n",
    "\n",
    "    def init_rule(self, if_then_pair):\n",
    "        self.if_ = []\n",
    "        self.if_len = len(if_then_pair[0])\n",
    "        self.then_ = if_then_pair[1][0]\n",
    "        for idx, i in enumerate(if_then_pair[0]):\n",
    "            self.if_.append(i)\n",
    "\n",
    "        # 替换some。。。，方便后续匹配\n",
    "        sub_words = ['something', 'someone']\n",
    "        for sub_word in sub_words:\n",
    "            self.then_ = self.then_.replace(sub_word, r'(.+)')\n",
    "            for idx, i in enumerate(self.if_):\n",
    "                self.if_[idx] = i.replace(sub_word, r'(.+)')\n",
    "        \n",
    "        # 替换成sen-polar对\n",
    "        self.then_ = (self.then_[0:-4], self.then_[-2])\n",
    "        for idx, i in enumerate(self.if_):\n",
    "            self.if_[idx] = (i[0:-4], i[-2])\n",
    "\n",
    "    # @staticmethod\n",
    "    def match(self,a,b):\n",
    "        matchObj = re.match( b[0], a[0], re.M|re.I)\n",
    "        return matchObj\n",
    "\n",
    "\n",
    "    def search(self, rules_list, facts_list ,deep):\n",
    "        self.next_step_list = []\n",
    "        sub_words = ['something', 'someone']\n",
    "        if deep <= 0:\n",
    "            return \n",
    "        \n",
    "        for i in self.if_:\n",
    "            next_step_list_per_if = []\n",
    "            self.next_step_list.append(next_step_list_per_if)\n",
    "            for rule in rules_list:\n",
    "                matchobj1 = self.match(i, rule.then_)\n",
    "                matchobj2 = self.match(rule.then_,i)\n",
    "                if matchobj1:\n",
    "                    \n",
    "\n",
    "                    new_node = node(rule.if_then_pair, 'rule')\n",
    "                    new_node.deep = deep-1\n",
    "                    if matchobj1.lastindex == 1:\n",
    "                        # print(new_node.if_)\n",
    "                        # print(new_node.then_)\n",
    "                        # print(matchobj1[1])\n",
    "                        new_node.then_ = (new_node.then_[0].replace(r'(.+)', matchobj1[1]),new_node.then_[1])\n",
    "                        \n",
    "                        for idx, item in enumerate(new_node.if_):\n",
    "                            new_node.if_[idx] = (item[0].replace(r'(.+)', matchobj1[1]),item[1])\n",
    "                             \n",
    "\n",
    "                    next_step_list_per_if.append(new_node)\n",
    "                    new_node.search(rules_list, facts_list,deep-1)\n",
    "                elif matchobj2:\n",
    "                    new_node = node(rule.if_then_pair, 'rule')\n",
    "                    new_node.deep = deep-1\n",
    "                    next_step_list_per_if.append(new_node)\n",
    "\n",
    "                    new_node.search(rules_list, facts_list,deep-1)\n",
    "                    # assert matchobj1.lastindex <= 1\n",
    "                        \n",
    "                        \n",
    "            for fact in facts_list:\n",
    "                matchobj1 = self.match(i, fact.then_)\n",
    "                matchobj2 = self.match(fact.then_,i)\n",
    "                if matchobj1 or matchobj2:\n",
    "                    new_node = node(fact.if_then_pair, 'fact')\n",
    "                    new_node.deep = deep-1\n",
    "                    next_step_list_per_if.append(new_node)\n",
    "            # self.next_step_list.append(next_step_list_per_if)\n",
    "\n",
    "deep = 5\n",
    "path = 'data/rule-reasoning-dataset-V2020.2.5.0/original/depth-{}/meta-train.jsonl'.format(deep)\n",
    "if_then_pairs = get_if_then_pairs(get_rules(path))\n",
    "facts = get_facts(path)\n",
    "qs = get_qs(path)\n",
    "\n",
    "instance_num = len(if_then_pairs)\n",
    "qs_list_all = []\n",
    "for i in tqdm(list(range(instance_num))[0:100]):\n",
    "    rules_list = []\n",
    "    facts_list = []\n",
    "    qs_list = []\n",
    "    for pair in if_then_pairs[i]:\n",
    "        rules_list.append(node(pair, 'rule'))\n",
    "    for fact in facts[i]:\n",
    "        facts_list.append(node(fact, 'fact'))\n",
    "    for q in qs[i]:\n",
    "        qs_list.append(node(q, 'ques'))\n",
    "    for q in qs_list:\n",
    "        q.search(rules_list,facts_list,deep+1)\n",
    "    qs_list_all.append(qs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_figure(q,output):\n",
    "    if len(q.next_step_list)!=0:\n",
    "        for n in q.next_step_list:\n",
    "            for i in n:\n",
    "                string = str(i.if_then_pair)+'-->'+str(q.if_then_pair)#+f\"_{str(i.deep)}_\"\n",
    "                # print(string)\n",
    "                string = string.replace(r'], [',r'::')\n",
    "                string = string.replace(r', ','&&')\n",
    "                string = string.replace(r'(','\\\\')\n",
    "                string = string.replace(r')','\\\\')\n",
    "                string = string.replace(r'[','\\\\')\n",
    "                string = string.replace(r']','\\\\')\n",
    "                string = string.replace('\\\"','')\n",
    "                string = string.replace('\\'','')\n",
    "                string = string.replace(' ','_')\n",
    "                string = string.replace('~','-')\n",
    "                output.append(string)\n",
    "                if i.type_=='rule':\n",
    "                    print_figure(i,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "with open('graph{}.md'.format(deep),'w') as f:\n",
    "    f.write('# ')\n",
    "    f.write(path)\n",
    "    f.write('\\n')\n",
    "    for j in range(len(qs_list_all[k])):\n",
    "        f.write('```mermaid\\ngraph TD\\n')\n",
    "        output = []\n",
    "        print_figure(qs_list_all[k][j],output)\n",
    "        output = list(set(output))\n",
    "        for i in output:\n",
    "            f.write(i)\n",
    "            f.write('\\n')\n",
    "        f.write('```\\n')\n",
    "        f.write('---\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic_width(q,total,max_deep):\n",
    "    if q.type_ != 'ques':\n",
    "        assert q.deep < max_deep or q.deep>=1\n",
    "        total[max_deep-q.deep]+=1\n",
    "    if q.next_step_list != None:\n",
    "        if len(q.next_step_list)!=0:\n",
    "            for n in q.next_step_list:\n",
    "                for i in n:\n",
    "                    statistic_width(i,total,max_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  3  5  9 11  9]\n",
      "[ 1  4  3  7 11 10]\n",
      "[ 1  4  3  7 11 10]\n",
      "[ 2  4  3  6 10 10]\n",
      "[ 2  1  2  4 13 11]\n",
      "[ 1  1  3  9 13 13]\n",
      "[ 1  1  5  5 13 12]\n",
      "[ 1  1  5  5 13 12]\n",
      "8\n",
      "2100\n"
     ]
    }
   ],
   "source": [
    "with open('typical_graph{}.md'.format(deep),'w') as f:\n",
    "    f.write('# ')\n",
    "    f.write(path)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    total_num = 0\n",
    "    typical_num = 0\n",
    "    for qs_list in qs_list_all:\n",
    "        for q in qs_list:\n",
    "            total_num+=1\n",
    "            total = np.zeros(deep+1).astype(int)\n",
    "            statistic_width(q,total,deep)\n",
    "            \n",
    "            if total.max() >=10 and total.argmax()!=deep:\n",
    "                typical_num += 1\n",
    "                print(total)\n",
    "                f.write(str(total.max()))\n",
    "                f.write(' ')\n",
    "                f.write(str(total.argmax()))\n",
    "                f.write('\\n')\n",
    "                f.write('```mermaid\\ngraph TD\\n')\n",
    "                output = []\n",
    "                print_figure(q,output)\n",
    "                output = list(set(output))\n",
    "                for i in output:\n",
    "                    f.write(i)\n",
    "                    f.write('\\n')\n",
    "                f.write('```\\n')\n",
    "                f.write('---\\n')\n",
    "    print(int(typical_num))\n",
    "    print(total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46ce47a2681318a5fd4609ecd91fb5bdbe2f4580b696868b796c60380cb3e01a"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('bert_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
